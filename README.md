# ğŸ“Š Plateforme d'Analyse des Immobilisations et Amortissements

## ğŸ¯ Introduction

Cette plateforme d'analyse automatisÃ©e permet la visualisation et le suivi des immobilisations et amortissements Ã  partir des donnÃ©es OpenData Paris. Le systÃ¨me extrait, transforme et charge (ETL) automatiquement les donnÃ©es publiques, puis les prÃ©sente via une interface Streamlit intuitive avec des tableaux de bord interactifs gÃ©nÃ©rÃ©s par Apache Superset.

### Objectifs du Projet

- **Automatisation complÃ¨te** : Pipeline ETL autonome pour la collecte et le traitement des donnÃ©es
- **Visualisation moderne** : Interface Streamlit avec dashboards statiques exportÃ©s depuis Superset
- **Architecture cloud-ready** : ConformitÃ© aux principes 12-Factor App
- **Production-ready** : Containerisation Docker, healthchecks, logging professionnel

### FonctionnalitÃ©s Principales

âœ… **ETL AutomatisÃ©** : Extraction par batch depuis l'API OpenData Paris (1000 enregistrements/batch)  
âœ… **Transformation AvancÃ©e** : Calcul automatique des champs dÃ©rivÃ©s (taux d'amortissement, Ã¢ge, valeur restante)  
âœ… **Base de DonnÃ©es MySQL** : Stockage optimisÃ© avec indexes et contraintes  
âœ… **Dashboards Superset** : Visualisations avancÃ©es (acquisitions, rÃ©partitions, analyses temporelles)  
âœ… **Interface Streamlit** : Navigation intuitive avec 3 pages (Accueil, Vue Executive, Analyse Temporelle)  
âœ… **Mode Statique** : Affichage des dashboards via images JPG (pas de requÃªtes SQL en temps rÃ©el)

---

## ğŸ—ï¸ Architecture ComplÃ¨te

### Vue d'Ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PLATEFORME D'ANALYSE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
        â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ETL        â”‚â”€â”€â”€â”€â–¶â”‚   MySQL      â”‚â—€â”€â”€â”€â”€â”‚  Superset    â”‚
â”‚   Python     â”‚     â”‚   Database   â”‚     â”‚  Analytics   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
        â”‚                     â”‚                     â–¼
        â”‚                     â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Streamlit   â”‚
        â”‚                                  â”‚  Frontend    â”‚
        â”‚                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                         â”‚
        â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenData API â”‚                         â”‚   Utilisateurâ”‚
â”‚ Paris        â”‚                         â”‚   Final      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Services Docker Compose

| Service | Image/Build | Port | RÃ´le | DÃ©pendances |
|---------|-------------|------|------|-------------|
| **mysql** | `mysql:8.0` | 3306 | Base de donnÃ©es principale | - |
| **db_init** | `mysql:8.0` | - | Initialisation du schÃ©ma | mysql (healthy) |
| **etl** | `./etl` (custom) | - | Pipeline ETL automatisÃ© | mysql (healthy) |
| **superset** | `./superset` (custom) | 8088 | Plateforme BI et dashboards | mysql |
| **streamlit** | `./frontend` (custom) | 8501 | Interface utilisateur web | superset |
| **adminer** | `adminer:latest` | 8080 | Administration base de donnÃ©es | mysql |

### Stack Technique

#### Backend & Data
- **Python 3.11** : Langage principal pour ETL et frontend
- **MySQL 8.0** : Base de donnÃ©es relationnelle
- **SQLAlchemy** : ORM pour les interactions base de donnÃ©es
- **Pandas** : Manipulation et transformation des donnÃ©es
- **Apache Superset 3.1.0** : Plateforme de business intelligence

#### Frontend
- **Streamlit 1.29.0** : Framework web pour interface utilisateur
- **Pillow 10.1.0** : Traitement et affichage d'images

#### Infrastructure
- **Docker & Docker Compose** : Containerisation et orchestration
- **Git** : ContrÃ´le de version (branche: `restore-V3`)

---

## ğŸ“ Structure du Projet

```
immobilisations_amortissements/
â”‚
â”œâ”€â”€ docker-compose.yml          # Orchestration des services
â”œâ”€â”€ .env.example                # Template de configuration
â”œâ”€â”€ .gitignore                  # Fichiers exclus du versioning
â”œâ”€â”€ README.md                   # Documentation (ce fichier)
â”‚
â”œâ”€â”€ etl/                        # ğŸ”§ Pipeline ETL
â”‚   â”œâ”€â”€ Dockerfile              # Image Python pour ETL
â”‚   â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”‚   â”œâ”€â”€ entrypoint.sh           # Script de dÃ©marrage
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.py             # Orchestrateur principal ETL
â”‚       â”œâ”€â”€ config.py           # Configuration centralisÃ©e
â”‚       â”œâ”€â”€ extract/
â”‚       â”‚   â””â”€â”€ extract.py      # Extraction API OpenData
â”‚       â”œâ”€â”€ transform/
â”‚       â”‚   â””â”€â”€ transform.py    # Transformation et enrichissement
â”‚       â”œâ”€â”€ load/
â”‚       â”‚   â””â”€â”€ load.py         # Chargement MySQL
â”‚       â””â”€â”€ utils/
â”‚           â””â”€â”€ process.py      # Utilitaires de conversion
â”‚
â”œâ”€â”€ mysql/                      # ğŸ—„ï¸ Base de DonnÃ©es
â”‚   â”œâ”€â”€ init.sql                # SchÃ©ma et initialisation
â”‚   â””â”€â”€ run-init.sh             # Script d'initialisation
â”‚
â”œâ”€â”€ superset/                   # ğŸ“ˆ Business Intelligence
â”‚   â”œâ”€â”€ Dockerfile              # Image Superset personnalisÃ©e
â”‚   â”œâ”€â”€ superset_config.py      # Configuration Superset
â”‚   â”œâ”€â”€ init-superset.sh        # Initialisation automatique
â”‚   â””â”€â”€ dashboards/             # Exports des dashboards
â”‚       â”œâ”€â”€ dashboard_executive.json
â”‚       â””â”€â”€ dashboard_temporel.json
â”‚
â”œâ”€â”€ frontend/                   # ğŸ–¥ï¸ Interface Utilisateur
â”‚   â”œâ”€â”€ Dockerfile              # Image Streamlit
â”‚   â”œâ”€â”€ requirements.txt        # DÃ©pendances lÃ©gÃ¨res
â”‚   â”œâ”€â”€ Home.py                 # Page d'accueil
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ 1_ğŸ‘ï¸_Vue_Executive.py
â”‚   â”‚   â””â”€â”€ 2_ğŸ“…_Analyse_Temporelle.py
â”‚   â””â”€â”€ Dashboards/             # Images statiques des dashboards
â”‚       â”œâ”€â”€ Executive/
â”‚       â”‚   â”œâ”€â”€ nombre-total-d-actifs.jpg
â”‚       â”‚   â”œâ”€â”€ acquisitions.jpg
â”‚       â”‚   â”œâ”€â”€ repartition.jpg
â”‚       â”‚   â”œâ”€â”€ top-10.jpg
â”‚       â”‚   â”œâ”€â”€ collectivite.jpg
â”‚       â”‚   â””â”€â”€ full-dashboard.jpg
â”‚       â””â”€â”€ Temporel/
â”‚           â”œâ”€â”€ acquisitions-annee.jpg
â”‚           â”œâ”€â”€ acquisitions-trimestre.jpg
â”‚           â”œâ”€â”€ acquisitions-mois.jpg
â”‚           â”œâ”€â”€ amortissement-cumule.jpg
â”‚           â””â”€â”€ full-dashboard.jpg
â”‚
â””â”€â”€ notebooks/                  # ğŸ““ Jupyter notebooks (analyse ad-hoc)
```

---

## ğŸ”„ Pipeline ETL DÃ©taillÃ©

### 1ï¸âƒ£ Extraction (`etl/src/extract/extract.py`)

**Source** : API OpenData Paris  
**MÃ©thode** : Pagination automatique avec gÃ©nÃ©rateur Python  
**Batch Size** : 1000 enregistrements par requÃªte  
**Gestion d'erreurs** : Retry sur timeout, fallback pour rÃ©ponses liste

```python
def fetch_records_in_batches(rows=1000):
    """GÃ©nÃ©rateur pour extraire les enregistrements par batch"""
    # Pagination automatique avec offset
    # Timeout 120s, gestion des erreurs 400/500
```

### 2ï¸âƒ£ Transformation (`etl/src/transform/transform.py`)

**SchÃ©ma Cible** : 12 colonnes typÃ©es
- `ndeg_immobilisation` (string, PK)
- `publication` (string)
- `collectivite` (string)
- `nature` (string)
- `date_acquisition`, `date_mise_en_service`, `date_fin_amortissement` (date)
- `valeur_acquisition`, `valeur_residuelle`, `dotation_amortissement` (decimal)
- `duree_amortissement` (int)
- `informations_complementaires` (text)

**Champs DÃ©rivÃ©s CalculÃ©s** :
- `taux_amortissement` : Taux annuel d'amortissement (%)
- `annee_acquisition`, `mois_acquisition`, `jour_acquisition`, `trimestre_acquisition`
- `age_immobilisation` : Ã‚ge en annÃ©es depuis l'acquisition
- `amortissement_total` : Montant total amorti Ã  ce jour
- `pct_valeur_restante` : Pourcentage de valeur rÃ©siduelle

**Flags QualitÃ©** :
- `is_complete` : Tous les champs essentiels prÃ©sents
- `is_depreciation_complete` : Amortissement terminÃ©

### 3ï¸âƒ£ Chargement (`etl/src/load/load.py`)

**StratÃ©gie** : UPSERT (INSERT ... ON DUPLICATE KEY UPDATE)  
**Transaction** : Rollback automatique en cas d'erreur  
**Performance** : Bulk insert avec SQLAlchemy  
**Sanitization** : Conversion NaN/Infinity avant insertion

```python
def upsert_immobilisations(df, table_name):
    """Insertion en masse avec gestion des transactions"""
    # Auto-crÃ©ation de table si nÃ©cessaire
    # Rollback sur erreur
```

---

## ğŸ¨ Interface Streamlit

### Architecture Multi-Pages

#### ğŸ  **Page d'Accueil** (`Home.py`)
- **Statistiques** : Compteurs d'images par dashboard
- **Navigation** : Cards cliquables vers les dashboards
- **Design** : Gradient bleu (#667eea â†’ #764ba2), cards blanches avec ombres

#### ğŸ‘ï¸ **Vue Executive** (`1_ğŸ‘ï¸_Vue_Executive.py`)
- **Mode 1** : Dashboard complet (image unique)
- **Mode 2** : Graphiques dÃ©taillÃ©s en onglets
  - Nombre total d'actifs
  - Acquisitions
  - RÃ©partition
  - Top 10
  - Par collectivitÃ©
- **FonctionnalitÃ©s** : TÃ©lÃ©chargement individuel des images

#### ğŸ“… **Analyse Temporelle** (`2_ğŸ“…_Analyse_Temporelle.py`)
- **Mode 1** : Dashboard temporel complet
- **Mode 2** : Analyses dÃ©taillÃ©es
  - Acquisitions par annÃ©e
  - Acquisitions par trimestre
  - Acquisitions par mois
  - Amortissement cumulÃ©
- **Design** : Gradient violet, navigation par onglets

### Style Visuel

**ThÃ¨me Principal** :
- Background : Gradient bleu (#667eea â†’ #764ba2)
- Cards : Blanc avec ombres portÃ©es
- Sidebar : Gradient bleu foncÃ© (#1e3a8a â†’ #1e40af)
- Typographie : Titres noirs, texte gris (#475569)

---

## ğŸš€ Installation et DÃ©marrage

### PrÃ©requis

- **Docker** : Version 20.10+
- **Docker Compose** : Version 2.0+
- **Git** : Pour cloner le repository
- **Ports disponibles** : 3306 (MySQL), 8080 (Adminer), 8088 (Superset), 8501 (Streamlit)

### Configuration Initiale

1ï¸âƒ£ **Cloner le repository**
```powershell
git clone <repository-url>
cd immobilisations_amortissements
git checkout restore-V3
```

2ï¸âƒ£ **Configurer les variables d'environnement**
```powershell
# Copier le template
cp .env.example .env

# Ã‰diter .env avec vos valeurs
notepad .env
```

**Variables essentielles Ã  modifier** :
```bash
# SÃ©curitÃ© (OBLIGATOIRE Ã  changer)
MYSQL_ROOT_PASSWORD=VotreMotDePasseSecurise123
MYSQL_PASSWORD=VotreMotDePasseUser456
SUPERSET_ADMIN_PASSWORD=VotreMotDePasseSupersetXYZ
SUPERSET_SECRET_KEY=VotreCleSecrete789ABC

# API OpenData Paris (obligatoire)
DATASET_API_URL=https://opendata.paris.fr/api/records/1.0/search/?dataset=immobilisations-incorporelles-amortissements-reprise
```

3ï¸âƒ£ **Lancer la plateforme**
```powershell
# Build et dÃ©marrage de tous les services
docker-compose up -d --build

# VÃ©rifier les statuts
docker-compose ps

# Suivre les logs (optionnel)
docker-compose logs -f
```

### Ordre de DÃ©marrage

Docker Compose gÃ¨re automatiquement les dÃ©pendances :
1. **MySQL** dÃ©marre en premier (healthcheck actif)
2. **db_init** initialise le schÃ©ma une fois MySQL prÃªt
3. **ETL** lance l'extraction aprÃ¨s la base prÃªte
4. **Superset** dÃ©marre en parallÃ¨le
5. **Streamlit** dÃ©marre aprÃ¨s Superset
6. **Adminer** dÃ©marre en parallÃ¨le

### AccÃ¨s aux Services

| Service | URL | Identifiants |
|---------|-----|-------------|
| **Streamlit** | http://localhost:8501 | - (pas d'auth) |
| **Superset** | http://localhost:8088 | `.env` SUPERSET_ADMIN_USER / SUPERSET_ADMIN_PASSWORD |
| **Adminer** | http://localhost:8080 | Serveur: mysql, User: `.env` MYSQL_USER |
| **MySQL** | localhost:3306 | User: `.env` MYSQL_USER |

---

## ğŸ› ï¸ OpÃ©rations Courantes

### Relancer l'ETL Manuellement
```powershell
docker-compose restart etl
docker-compose logs -f etl
```

### VÃ©rifier les DonnÃ©es MySQL
```powershell
# Via Adminer (interface web)
# â†’ http://localhost:8080

# Via CLI
docker exec -it <mysql-container-id> mysql -u admin -p paris_immobilisations_db
```

### Rebuild un Service SpÃ©cifique
```powershell
# Exemple : reconstruire Streamlit aprÃ¨s modification
docker-compose up -d --build streamlit
```

### ArrÃªter la Plateforme
```powershell
# ArrÃªt propre
docker-compose down

# ArrÃªt avec suppression des volumes (âš ï¸ perte de donnÃ©es)
docker-compose down -v
```

### Consulter les Logs
```powershell
# Tous les services
docker-compose logs -f

# Service spÃ©cifique
docker-compose logs -f etl
docker-compose logs -f streamlit

# DerniÃ¨res 200 lignes
docker logs <container-name> --tail 200
```

---

## ğŸ“Š SchÃ©ma de Base de DonnÃ©es

### Table : `immobilisations`

```sql
CREATE TABLE IF NOT EXISTS immobilisations (
    id INT AUTO_INCREMENT PRIMARY KEY,
    ndeg_immobilisation VARCHAR(100) UNIQUE NOT NULL,
    publication VARCHAR(255),
    collectivite VARCHAR(255),
    nature VARCHAR(255),
    date_acquisition DATE,
    date_mise_en_service DATE,
    date_fin_amortissement DATE,
    valeur_acquisition DECIMAL(15,2),
    valeur_residuelle DECIMAL(15,2),
    dotation_amortissement DECIMAL(15,2),
    duree_amortissement INT,
    informations_complementaires TEXT,
    
    -- Champs dÃ©rivÃ©s calculÃ©s par l'ETL
    taux_amortissement DECIMAL(5,2),
    annee_acquisition INT,
    mois_acquisition INT,
    jour_acquisition INT,
    trimestre_acquisition INT,
    age_immobilisation DECIMAL(10,2),
    amortissement_total DECIMAL(15,2),
    pct_valeur_restante DECIMAL(5,2),
    
    -- Flags qualitÃ©
    is_complete BOOLEAN,
    is_depreciation_complete BOOLEAN,
    
    -- MÃ©tadonnÃ©es
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    -- Indexes pour performance
    INDEX idx_collectivite (collectivite),
    INDEX idx_nature (nature),
    INDEX idx_date_acquisition (date_acquisition),
    INDEX idx_annee_acquisition (annee_acquisition)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
```

### VolumÃ©trie

- **~1000-5000 enregistrements** (selon disponibilitÃ© OpenData)
- **Refresh** : Ã€ chaque exÃ©cution ETL (UPSERT)
- **Indexes** : Optimisation des requÃªtes Superset

---

## âœ… ConformitÃ© 12-Factor App

| Facteur | Statut | ImplÃ©mentation |
|---------|--------|----------------|
| **I. Codebase** | âœ… | Repository Git unique, branche `restore-V3` |
| **II. Dependencies** | âœ… | `requirements.txt` pour Python, images Docker versionnÃ©es |
| **III. Config** | âœ… | Variables d'environnement via `.env` (12-factor compliant) |
| **IV. Backing Services** | âœ… | MySQL, Superset traitÃ©s comme ressources attachables |
| **V. Build/Release/Run** | âœ… | Docker build â†’ Docker Compose up (sÃ©paration stricte) |
| **VI. Processes** | âœ… | Services stateless, Ã©tat en base MySQL |
| **VII. Port Binding** | âœ… | Chaque service expose son propre port |
| **VIII. Concurrency** | âš ï¸ | ETL single-process, scalable via Docker replicas |
| **IX. Disposability** | âœ… | Healthchecks, graceful shutdown, entrypoints configurÃ©s |
| **X. Dev/Prod Parity** | âœ… | Docker garantit environnements identiques |
| **XI. Logs** | âš ï¸ | Logs stdout/stderr, pas de centralisation externe |
| **XII. Admin Processes** | âœ… | Scripts run-init.sh, entrypoint.sh pour tÃ¢ches admin |

**Score Global** : 8/12 (67%) âœ… Production-ready avec amÃ©liorations possibles

---

## ğŸ› Troubleshooting

### ProblÃ¨me : Service ne dÃ©marre pas

**Solution** :
```powershell
# VÃ©rifier les logs
docker-compose logs <service-name>

# Rebuild complet
docker-compose down
docker-compose up -d --build
```

### ProblÃ¨me : Healthcheck MySQL Ã©choue

**Solution** :
```powershell
# VÃ©rifier l'Ã©tat
docker-compose ps

# Si mysql en "unhealthy" â†’ attendre 30-60s
# Ou redÃ©marrer MySQL
docker-compose restart mysql
```

### ProblÃ¨me : ETL ne trouve pas les donnÃ©es

**SymptÃ´mes** : Logs "SUCCESS: 0 records processed"

**Solution** :
1. VÃ©rifier `DATASET_API_URL` dans `.env`
2. Tester l'API manuellement : `curl <DATASET_API_URL>`
3. VÃ©rifier les logs ETL : `docker-compose logs etl`

### ProblÃ¨me : Streamlit affiche "Image non disponible"

**Solution** :
1. VÃ©rifier que les images existent : `ls frontend/Dashboards/Executive/`
2. Rebuild Streamlit : `docker-compose up -d --build streamlit`
3. VÃ©rifier les permissions des fichiers

### ProblÃ¨me : Superset ne se connecte pas Ã  MySQL

**Solution** :
```powershell
# VÃ©rifier les credentials dans .env
# Tester la connexion MySQL
docker exec -it <mysql-container> mysql -u admin -p

# Reconstruire Superset
docker-compose up -d --build superset
```

---

## ğŸ“ Logging et Monitoring

### Format des Logs

**ETL** :
```
[2024-11-24 10:30:45] INFO: Starting ETL pipeline
[2024-11-24 10:30:50] INFO: STEP 1 - Extraction from API
[2024-11-24 10:31:20] SUCCESS: 1000 records extracted
[2024-11-24 10:31:25] INFO: STEP 2 - Transformation
[2024-11-24 10:31:40] SUCCESS: 1000 records transformed
[2024-11-24 10:31:45] INFO: STEP 3 - Loading to MySQL
[2024-11-24 10:32:10] SUCCESS: 1000 records loaded
```

**Streamlit** :
```
INFO: Application started on port 8501
INFO: Loading dashboard images...
SUCCESS: 11 images loaded successfully
```

### Healthchecks

Tous les services ont des healthchecks configurÃ©s :
- **MySQL** : `mysqladmin ping` toutes les 10s
- **Superset** : HTTP check sur port 8088
- **Streamlit** : `curl http://localhost:8501/_stcore/health`

---

## ğŸ¤ Contribution

### Workflow de DÃ©veloppement

1. CrÃ©er une branche feature : `git checkout -b feature/ma-fonctionnalite`
2. DÃ©velopper et tester localement avec Docker Compose
3. Committer avec messages descriptifs en franÃ§ais
4. Push et crÃ©er une Pull Request

### Standards de Code

- **Python** : PEP 8, docstrings en franÃ§ais
- **SQL** : Nommage en snake_case
- **Docker** : Multi-stage builds si possible
- **Logs** : Format professionnel, pas d'emojis

---

## ğŸ“š Ressources

### Documentation Externe

- [Streamlit Documentation](https://docs.streamlit.io/)
- [Apache Superset](https://superset.apache.org/docs/intro)
- [OpenData Paris API](https://opendata.paris.fr/explore/)
- [MySQL 8.0 Reference](https://dev.mysql.com/doc/refman/8.0/en/)
- [12-Factor App Methodology](https://12factor.net/)

### Contact & Support

- **Repository** : AlaDdin0709/immobilisations_amortissements
- **Branche** : restore-V3
- **Issues** : Utiliser GitHub Issues pour les bugs et demandes de fonctionnalitÃ©s

---

## ğŸ“„ Licence

Ce projet est destinÃ© Ã  des fins Ã©ducatives et d'analyse de donnÃ©es publiques.

---

**DerniÃ¨re mise Ã  jour** : 24 novembre 2025  
**Version** : 1.0.0  
**Mainteneur** : AlaDdin0709
